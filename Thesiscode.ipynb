{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! STEP1: In terminal:\n",
    "#! source Thesis/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "from mne.filter import filter_data\n",
    "from mne.preprocessing import ICA\n",
    "from autoreject import AutoReject\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File selection/Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data = []\n",
    "All_resting = []\n",
    "All_audio = []\n",
    "All_video = []\n",
    "\n",
    "Migraine_resting = []\n",
    "Migraine_audio = []\n",
    "Migraine_video = []\n",
    "\n",
    "Control_resting = []\n",
    "Control_audio = []\n",
    "Control_video = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting all the file names into their respective categories\n",
    "for File in os.listdir('Dataset'):\n",
    "    if \".bdf\" in File: # only looking at the EEG files\n",
    "        All_data.append(File)\n",
    "        if \"Resting\" in File: # selecting only resting-state files\n",
    "            All_resting.append(File)\n",
    "            if File[0] == \"M\": # selecting migraineurs among resting-state files\n",
    "                Migraine_resting.append(File)\n",
    "            elif File[0] == \"C\": # selecting control group among resting-state files\n",
    "                Control_resting.append(File)\n",
    "        elif \"SSAEP\" in File: # selecting only audio stimulation\n",
    "            All_audio.append(File)\n",
    "            if File[0] == \"M\": # selecting migraineurs among audio stimulation files\n",
    "                Migraine_audio.append(File)\n",
    "            elif File[0] == \"C\": # selecting control group among audio stimulation files\n",
    "                Control_audio.append(File)\n",
    "        elif \"SSVEP\" in File: # selecting only video stimulation\n",
    "            All_video.append(File)\n",
    "            if File[0] == \"M\": # selecting migraineurs among video stimulation files\n",
    "                Migraine_video.append(File)\n",
    "            elif File[0] == \"C\": # selecting control group among video stimulation files\n",
    "                Control_video.append(File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#? To be used when turning lists into dataframes (if needed)\n",
    "All = {\"Resting\": All_resting, \"Audio\": All_audio, \"Video\": All_video}\n",
    "Migraines = {\"Resting\": Migraine_resting, \"Audio\": Migraine_audio, \"Video\": Migraine_video}\n",
    "Controls = {\"Resting\": Control_resting, \"Audio\": Control_audio, \"Video\": Control_video}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 39 39 39\n",
      "17 16 17\n",
      "['M10_SSAEP.bdf', 'M11_SSAEP.bdf', 'M12_SSAEP.bdf', 'M14_SSAEP.bdf', 'M16_SSAEP.bdf', 'M17_SSAEP.bdf', 'M18_SSAEP.bdf', 'M1_SSAEP.bdf', 'M2_SSAEP.bdf', 'M3_SSAEP.bdf', 'M4_SSAEP.bdf', 'M5_SSAEP.bdf', 'M6_SSAEP.bdf', 'M7_SSAEP.bdf', 'M8_SSAEP.bdf', 'M9_SSAEP.bdf']\n",
      "21 22 21\n",
      "['C10_SSAEP.bdf', 'C11_SSAEP.bdf', 'C12_SSAEP.bdf', 'C13_SSAEP.bdf', 'C14_SSAEP.bdf', 'C14_SSAEP_2.bdf', 'C15_SSAEP.bdf', 'C16_SSAEP.bdf', 'C17_SSAEP.bdf', 'C18_SSAEP.bdf', 'C19_SSAEP.bdf', 'C1_SSAEP.bdf', 'C20_SSAEP.bdf', 'C21_SSAEP.bdf', 'C2_SSAEP.bdf', 'C3_SSAEP.bdf', 'C4_SSAEP.bdf', 'C5_SSAEP.bdf', 'C6_SSAEP.bdf', 'C7_SSAEP.bdf', 'C8_SSAEP.bdf', 'C9_SSAEP.bdf']\n"
     ]
    }
   ],
   "source": [
    "# File integrity inspection\n",
    "print(len(All_data), len(All_resting), len(All_audio), len(All_video))\n",
    "\n",
    "print(len(Migraine_resting), len(Migraine_audio), len(Migraine_video))\n",
    "print(Migraine_audio)\n",
    "#! Migraine patient 13 has no audio file\n",
    "\n",
    "print(len(Control_resting), len(Control_audio), len(Control_video))\n",
    "print(Control_audio)\n",
    "#! Control patient 14 has two audiofiles, maybe due to an interruption in the recording? --> documentation shows no info about this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the event ID's as per the documentation (EEG experiment protocol_Migraine_Brain_KiltHub_vF.pdf)\n",
    "resting_event_id = {\"block_start\": 1, \"block_end\": 2}\n",
    "\n",
    "stimulation_event_id = {\"4hz_stim_start\": 1, \"4hz_stim_keypress\":11, \"6hz_stim_start\": 2, \"6hz_stim_keypress\": 22}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the data for bad channels or artifacts\n",
    "\"\"\"\n",
    "for File in All_resting:\n",
    "    print(\"Now looking at: \" + File)\n",
    "    raw = mne.io.read_raw_bdf(f\"Dataset/{File}\")\n",
    "    events = mne.find_events(raw)\n",
    "    fig = mne.viz.plot_events(events, sfreq=raw.info[\"sfreq\"], first_samp=raw.first_samp, event_id=resting_event_id)\n",
    "    epochs = mne.Epochs(raw, events)\n",
    "    raw.plot()\n",
    "    epochs['1'].plot(events=True)\n",
    "\n",
    "for File in All_audio:\n",
    "    print(\"Now looking at: \" + File)\n",
    "    raw = mne.io.read_raw_bdf(f\"Dataset/{File}\")\n",
    "    events = mne.find_events(raw)\n",
    "    fig = mne.viz.plot_events(events, sfreq=raw.info[\"sfreq\"], first_samp=raw.first_samp, event_id=stimulation_event_id)\n",
    "    epochs = mne.Epochs(raw, events)\n",
    "    raw.plot()\n",
    "    epochs['1'].plot(events=True)\n",
    "\n",
    "for File in All_video:\n",
    "    print(\"Now looking at: \" + File)\n",
    "    raw = mne.io.read_raw_bdf(f\"Dataset/{File}\")\n",
    "    events = mne.find_events(raw)\n",
    "    fig = mne.viz.plot_events(events, sfreq=raw.info[\"sfreq\"], first_samp=raw.first_samp, event_id=stimulation_event_id)\n",
    "    epochs = mne.Epochs(raw, events)\n",
    "    raw.plot()\n",
    "    epochs['1'].plot(events=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evalution matrices\n",
    "\"\"\"\n",
    "## LOSS-ACC GRAPHS\n",
    "def loss_acc_graph(MODEL, modelname):\n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    plt.plot(MODEL.history['loss'], label=\"Loss\")\n",
    "    plt.plot(MODEL.history['val_loss'], label=\"Validation Loss\")\n",
    "    plt.title (modelname + \" Training/Validation Loss and Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(MODEL.history['accuracy'], label=\"Accuracy\")\n",
    "    plt.plot(MODEL.history['val_accuracy'], label=\"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#Conf matrix and Classification Report:\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def calculate_metrics(model, X_test, y_test, title):\n",
    "    # predict probabilities for test set\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # ensuring same format for both\n",
    "    y_pred=np.argmax(y_pred, axis=1)\n",
    "    y_test=np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # using classification report to get metrics\n",
    "    metrics = classification_report(y_test, y_pred, target_names=ordered_classes)\n",
    "    print(metrics)\n",
    "    \n",
    "    # confusion matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    p = sns.heatmap(matrix, annot=True, fmt='g')\n",
    "    p.set_xlabel(\"Predicted label\", fontsize = 20)\n",
    "    p.set_ylabel(\"True Label\", fontsize = 20)\n",
    "    p.xaxis.set_ticklabels([\"CBT\", \"CA\", \"LBT\", \"LQCC\", \"LA\"], rotation = 0)\n",
    "    p.yaxis.set_ticklabels(ordered_classes, rotation = 0)\n",
    "    plt.title (title)\n",
    "    plt.show()\n",
    "    \n",
    "#ROC curves\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay, auc, roc_auc_score\n",
    "\n",
    "def roc(model, X_test, y_test,title):\n",
    "      # predict probabilities for test set\n",
    "      y_pred = model.predict(X_test, verbose=0)\n",
    "\n",
    "      # initializing the plot\n",
    "      plt.figure()\n",
    "      plt.plot([0, 1], [0, 1], 'k--')\n",
    "      plt.title (title)\n",
    "      plt.xlabel('False Positive Rate')\n",
    "      plt.ylabel('True Positive Rate')\n",
    "      \n",
    "      \n",
    "      # computing micro and macro AUC scores #TODO: does not correctly plot micro and macro AUC\n",
    "      micro_auc = roc_auc_score(y_test, y_pred, average=\"micro\", multi_class=\"ovr\")\n",
    "      macro_auc = roc_auc_score(y_test, y_pred, average=\"macro\", multi_class=\"ovr\")\n",
    "      plt.plot(micro_auc, label=f'ROC (micro) - area = {micro_auc:.3f}')\n",
    "      plt.plot(macro_auc, label=f'ROC (macro) - area = {macro_auc:.3f}')\n",
    "      \n",
    "      # computing AUC scores per class and plotting them\n",
    "      for i in range(5):\n",
    "            fpr, tpr, threshold = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "            auc_val = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'ROC ({ordered_classes[i]}) - area = {auc_val:.3f}')\n",
    "      \n",
    "      plt.legend(loc=\"lower right\")\n",
    "      plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 2548x1367 with 4 Axes>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "# For testing purposes\n",
    "#raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data, finding events, setting up epochs\n",
    "raw = mne.io.read_raw_bdf(f\"Dataset/{All_resting[0]}\", preload=True)\n",
    "events = mne.find_events(raw)\n",
    "epochs = mne.Epochs(raw, events, preload=True)\n",
    "raw.set_eeg_reference(ref_channels=['M1', 'M2']) #(i) EEG data were re-referenced offline to the average of the two mastoid electrodes\n",
    "raw.set_channel_types({'ECG':'ecg', 'Fp1':'eog'}) # setting up pre-existing channel ECG for heartbeat detection; Fp1 as eye-near channel is used as proxy for eye-related artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filt = raw.copy().filter(l_freq=0.1, h_freq=100) #(i) zero-phase Butterworth filter was used to filter the signals between 0.1 and 100 Hz;\n",
    "raw_filt.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for File in All_resting:\n",
    "    raw = mne.io.read_raw_bdf(f\"Dataset/{File}\", preload=True)\n",
    "    raw.set_eeg_reference(ref_channels=['M1', 'M2'])\n",
    "    raw.set_channel_types({'ECG':'ecg', 'Fp1':'eog'})\n",
    "    raw2 = raw.copy()\n",
    "    raw2.info[\"bads\"] = []\n",
    "    events = mne.find_events(raw2)\n",
    "    epochs = mne.Epochs(raw2, events=events)[\"2\"].average().plot()\n",
    "#TODO (ii) noisy channels were detected visually and interpolated (this was done in 0.95% of electrodes from the migraine group and 0.3% from the control group); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since data is not supposed to be filtered prior to ICA, a copy is used to conduct the ica. 50 components have been chosen to limit the time it takes (while still explaining ~96% of variation)\n",
    "ica_filt_raw = raw.copy().filter(l_freq=1.0, h_freq=None)\n",
    "ica = ICA(n_components=50, max_iter=\"auto\", random_state=97)\n",
    "ica.fit(ica_filt_raw)\n",
    "ica\n",
    "\n",
    "explained_var_ratio = ica.get_explained_variance_ratio(ica_filt_raw)\n",
    "for channel_type, ratio in explained_var_ratio.items():\n",
    "    print(\n",
    "        f\"Fraction of {channel_type} variance explained by all components: \" f\"{ratio}\"\n",
    "    )\n",
    "    \n",
    "raw.load_data()\n",
    "ica.plot_sources(raw, show_scrollbars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out which components to exclude\n",
    "ica.exclude = []\n",
    "# find which ICs match the EOG/ECG patterns\n",
    "eog_indices, eog_scores = ica.find_bads_eog(raw)\n",
    "ica.exclude = eog_indices\n",
    "ecg_indices, ecg_scores = ica.find_bads_ecg(raw, method=\"correlation\", threshold=\"auto\")\n",
    "ica.exclude += ecg_indices\n",
    "\n",
    "# barplot of ICA component \"EOG match\" scores\n",
    "ica.plot_scores(eog_scores)\n",
    "ica.plot_scores(ecg_scores)\n",
    "# plot ICs applied to raw data, with EOG/ECG matches highlighted\n",
    "ica.plot_sources(raw, show_scrollbars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(iv) for the resting state trials, 2-s non-overlapping time intervals were extracted; and \n",
    "#(v)  these 2-s time intervals were passed through zero-phase Kaiser bandpass filters to extract 5 frequency bands of delta (0.5 − 3 Hz), theta (4 − 7 Hz), alpha (8 − 12 Hz), beta (12 − 30 Hz) and gamma (30 − 100 Hz). \n",
    "# A lowpass filter with cut-off frequency of 30 Hz is standardly used for noisy EEG data64. \n",
    "\n",
    "epoch_length = 2  # Length of each epoch in seconds\n",
    "sfreq = raw.info['sfreq']  # Sampling frequency of the data\n",
    "\n",
    "# Extract 2-second non-overlapping epochs\n",
    "n_samples_per_epoch = int(epoch_length * sfreq)\n",
    "n_epochs = len(raw.times) // n_samples_per_epoch\n",
    "epochs_data = np.array_split(raw.get_data(), n_epochs, axis=1)\n",
    "\n",
    "# Initialize lists to store filtered data for each frequency band\n",
    "delta_data = []\n",
    "theta_data = []\n",
    "alpha_data = []\n",
    "beta_data = []\n",
    "gamma_data = []\n",
    "\n",
    "# Define frequency bands\n",
    "freq_bands = {\n",
    "    'delta': (0.5, 3),\n",
    "    'theta': (4, 7),\n",
    "    'alpha': (8, 12),\n",
    "    'beta': (12, 30),\n",
    "    'gamma': (30, 100)\n",
    "}\n",
    "\n",
    "# Apply zero-phase Kaiser bandpass filters to extract frequency bands\n",
    "for epoch_data in epochs_data:\n",
    "    for freq_band, (fmin, fmax) in freq_bands.items():\n",
    "        filtered_data = filter_data(epoch_data, sfreq, fmin, fmax, method='fir', phase='zero')\n",
    "        if freq_band == 'delta':\n",
    "            delta_data.append(filtered_data)\n",
    "        elif freq_band == 'theta':\n",
    "            theta_data.append(filtered_data)\n",
    "        elif freq_band == 'alpha':\n",
    "            alpha_data.append(filtered_data)\n",
    "        elif freq_band == 'beta':\n",
    "            beta_data.append(filtered_data)\n",
    "        elif freq_band == 'gamma':\n",
    "            gamma_data.append(filtered_data)\n",
    "\n",
    "# Concatenate the filtered data arrays\n",
    "delta_data = np.concatenate(delta_data, axis=1)\n",
    "theta_data = np.concatenate(theta_data, axis=1)\n",
    "alpha_data = np.concatenate(alpha_data, axis=1)\n",
    "beta_data = np.concatenate(beta_data, axis=1)\n",
    "gamma_data = np.concatenate(gamma_data, axis=1)\n",
    "\n",
    "# Apply lowpass filter with cutoff frequency of 30 Hz\n",
    "delta_data = filter_data(delta_data, sfreq, None, 30, method='fir', phase='zero')\n",
    "theta_data = filter_data(theta_data, sfreq, None, 30, method='fir', phase='zero')\n",
    "alpha_data = filter_data(alpha_data, sfreq, None, 30, method='fir', phase='zero')\n",
    "beta_data = filter_data(beta_data, sfreq, None, 30, method='fir', phase='zero')\n",
    "gamma_data = filter_data(gamma_data, sfreq, None, 30, method='fir', phase='zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the event points\n",
    "fig = mne.viz.plot_events(events, sfreq=raw.info[\"sfreq\"], first_samp=raw.first_samp, event_id=resting_event_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: Implement pre-processing strategy as written by chamanzar et al:\n",
    "#(i) EEG data were re-referenced offline to the average of the two mastoid electrodes and a zero-phase Butterworth filter was used to filter the signals between 0.1 and 100 Hz; \n",
    "#! Why is this done? --> The mastoids are channels which are mean to pick up all the environmental noise, while not capturing brain activity. Sort of a \"blueprint\" for what to count as artifacts\n",
    "\"\"\"\n",
    "for File in All_resting:\n",
    "    print(\"Now filtering: \" + File)\n",
    "    raw = mne.io.read_raw_bdf(f\"Dataset/{File}\", preload=True)\n",
    "    raw.set_eeg_reference(ref_channels=['M1', 'M2'])\n",
    "    raw_filtered = filter_data(raw.get_data(), sfreq=raw.info['sfreq'], l_freq=0.1, h_freq=100, method='fir', verbose=False)\n",
    "    raw._data = raw_filtered\n",
    "    #raw.plot(block=True)\n",
    "\"\"\"\n",
    "\n",
    "#(iv) for the visual and auditory trials, the first 2 s after the stimulus onset were extracted, \n",
    "#However, we chose to keep the high-frequency gamma band given that: \n",
    "#(a) the Biosemi ActiveTwo system has active electrodes and it can tolerate high electrode impedances, \n",
    "#(b) the participants were seated inside a Faraday cage during the EEG recording to reduce the electromagnetic interferences and \n",
    "#(c) we detected and interpolated noisy channels, as stated in Step (ii) of the preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: set up CV (LOOCV and 5-fold random CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! Split up the recordings into parts, BUT: Make sure that all parts of one participant end up in the same fold\n",
    "#! Classifier will evaluate each epoch separately, but could be useful to aggregate them --> if majority of the evaluations classify patient, then it is considered a patient"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
